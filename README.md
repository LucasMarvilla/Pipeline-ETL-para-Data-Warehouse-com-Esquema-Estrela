# üìä Projeto: Pipeline + Data Warehouse

**Tecnologias utilizadas:** Python ¬∑ SQL ¬∑ Apache Airflow ¬∑ PostgreSQL ¬∑ pgAdmin ¬∑ Data Warehouse

## üìù Descri√ß√£o do Projeto

Este projeto teve como objetivo a constru√ß√£o de um mini **Data Warehouse** a partir do conjunto de dados da [Olist (Kaggle)](https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce), que cont√©m informa√ß√µes completas sobre um e-commerce brasileiro.

Os dados estavam originalmente **distribu√≠dos em diversos arquivos CSV separados**, representando entidades como pedidos, produtos, pagamentos, avalia√ß√µes, clientes, entre outros. A partir disso:

- Analisei o **data esquema original** para entender as rela√ß√µes entre os arquivos;
- Modelei um **Data Warehouse com esquema estrela**, consolidando as principais entidades em tabelas dimens√£o e fato;
- Realizei a **limpeza, transforma√ß√£o e integra√ß√£o dos dados** utilizando Python;
- Estruturei o banco de dados relacional no **PostgreSQL**;
- Utilize o **pgAdmin** para **criar o diagrama ERD** (Entidade-Relacionamento) do modelo implementado;
- Automatizei o processo de carga com um pipeline criado em **Apache Airflow**.

## üóÇÔ∏è Data Esquema Original

Abaixo est√° o diagrama do esquema original dos dados dispon√≠veis nos arquivos CSV da Olist:

![Data Esquema Original](Diagramas\Data_Schema.png)

## üåü Modelagem Estrela

Transformei o esquema anterior em um modelo estrela com foco na an√°lise de vendas:

### üî∏ Tabela Fato: `fato_vendas`
Cont√©m informa√ß√µes transacionais sobre cada item vendido:
- `order_id`, `order_item_id`
- `product_id`, `seller_id`, `customer_id`, `data_id`
- `price`, `freight_value`, `payment_value`
- `payment_type`, `review_score`, `order_status`
- `shipping_limit_date`

### üîπ Tabelas Dimens√£o:
- `dim_cliente`: Dados geogr√°ficos dos clientes
- `dim_produto`: Caracter√≠sticas dos produtos
- `dim_vendedor`: Localiza√ß√£o e identifica√ß√£o dos vendedores
- `dim_tempo`: Detalhes de datas (ano, m√™s, dia, dia da semana)
- `dim_pagamento`: Tipo e valor de pagamento
- `dim_avaliacao`: Notas e coment√°rios dos clientes

## üß≠ Diagrama ERD (PostgreSQL via pgAdmin)

O diagrama abaixo foi gerado a partir das tabelas criadas no **pgAdmin** com o modelo estrela:

![ERD - Modelo Estrela](Diagramas\diagrama_ERD.png)

## üéØ Resultados

Com a transforma√ß√£o dos dados para o modelo estrela, foi poss√≠vel:

- Realizar an√°lises mais eficientes com consultas SQL otimizadas;
- Cruzar m√©tricas de neg√≥cio com diferentes dimens√µes (tempo, localiza√ß√£o, produto, etc.);
- Ter uma base preparada para futuras integra√ß√µes com ferramentas de BI.



Este guia explica a sequ√™ncia correta de comandos para subir o Apache Airflow utilizando Docker Compose.

## Pr√©-requisitos

- Docker e Docker Compose instalados
- Projeto do Airflow com o arquivo `docker-compose.yaml` devidamente configurado

## Passo a passo

### 1. Inicializar o ambiente do Airflow

```bash
cd airflow/
```
Antes de subir os containers, √© necess√°rio inicializar o Airflow. Esse passo prepara o banco de dados, aplica as migra√ß√µes e cria o usu√°rio admin padr√£o.

```bash
docker compose up airflow-init
```

> ‚ö†Ô∏è Este comando deve ser executado **somente na primeira vez** ou sempre que os volumes forem removidos.

### 2. Subir os containers

Depois que a inicializa√ß√£o for conclu√≠da com sucesso, voc√™ pode subir todos os servi√ßos normalmente:

```bash
docker-compose up -d
```

### 3. Acessar a interface Web do Airflow
1. criar conex√£o do airflow com postgresql

```bash
docker exec -it projetoairflow-airflow-scheduler-1 airflow connections add 'postgres_etl' --conn-uri 'postgresql+psycopg2://airflow:airflow@postgres:5432/airflow'
```

2. A interface web geralmente estar√° dispon√≠vel no seguinte endere√ßo:


[http://localhost:8080]


Use as credenciais criadas durante a inicializa√ß√£o (`airflow-init`) para fazer login.
3. Fa√ßa login com as credenciais
   - **Username:** `airflow`
   - **Password:** `airflow`

### üîó Conex√£o ao PostgreSQL via pgAdmin

1. Acesse o pgAdmin no navegador:  
   [http://localhost:8081]

2. Fa√ßa login com as credenciais
   - **Email:** `admin@admin.com`
   - **Senha:** `admin`

3. Clique com o bot√£o direito em ‚ÄúServers‚Äù > **Create** > **Server**.

4. Na aba **General**, defina um nome como:
   - `Projeto` ou o que preferir.

5. Na aba **Connection**, insira:
   - **Host name/address:** `postgres`  
   - **Port:** `5432`  
   - **Username:** `airflow`  
   - **Password:** `airflow`
   - **database:** `airflow`  
   - Marque a op√ß√£o **Save Password**.

6. Clique em **Save**. Agora voc√™ pode acessar o banco `Projeto`.

### üîó visualiza√ß√£o no PostgreSQL via pgAdmin

1. expende servers -> airflow -> schemas -> tables -> 
- `dim_cliente`: Dados geogr√°ficos dos clientes
- `dim_produto`: Caracter√≠sticas dos produtos
- `dim_vendedor`: Localiza√ß√£o e identifica√ß√£o dos vendedores
- `dim_tempo`: Detalhes de datas (ano, m√™s, dia, dia da semana)
- `dim_pagamento`: Tipo e valor de pagamento
- `dim_avaliacao`: Notas e coment√°rios dos clientes